{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.modelUtils import *\n",
    "from utils.utils import *\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from casper import nethook\n",
    "from casper.nethook import *\n",
    "from utils.judgeUtils import *\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization\n",
    "\n",
    "Loading Llama-2-7b-chat model for representation intervention analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "mt = ModelAndTokenizer(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=(torch.float16 if \"20b\" in model_name else None),\n",
    "    device = 'cuda:0'\n",
    ")\n",
    "mt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = generate_input(mt.tokenizer, 'tell me a fun joke')\n",
    "test_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge Model Loading\n",
    "\n",
    "Loading the judge model to evaluate whether responses successfully jailbreak the safety mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading judge model...\")\n",
    "judge_tokenizer, judge_model_loaded = load_judge_model()\n",
    "print(\"Judge model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Loading benign and harmful prompts for representation-level intervention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"analysis_data/llama2_gcgs.json\",'r') as f:\n",
    "    gcgs = json.load(f)[:3]\n",
    "with open(\"analysis_data/llama2_autodan.json\",'r') as f:\n",
    "    autodan = json.load(f)[:3]\n",
    "import pandas as pd\n",
    "harmful_data = pd.read_csv(\"analysis_data/advbench_behaviors.csv\")['Behavior']\n",
    "harmful_questions = list(harmful_data)[:100]\n",
    "with open(\"analysis_data/alpaca_clean.json\",'r') as f:\n",
    "    alpaca = json.load(f)\n",
    "benign_questions = [p['instruction'] for p in alpaca][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Harmful questions: {len(harmful_questions)}\")\n",
    "print(f\"Benign questions: {len(benign_questions)}\")\n",
    "\n",
    "# %%\n",
    "# Format prompts using chat template\n",
    "harmful_prompts = [mt.tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": q}], \n",
    "                                                      tokenize=False, \n",
    "                                                      add_generation_prompt=True) \n",
    "                   for q in harmful_questions]\n",
    "\n",
    "benign_prompts = [mt.tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": q}], \n",
    "                                                     tokenize=False, \n",
    "                                                     add_generation_prompt=True) \n",
    "                  for q in benign_questions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Hidden States\n",
    "\n",
    "Collect hidden states from all transformer layers for both benign and harmful prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_hidden_states(mt, prompts, batch_size=8):\n",
    "    \"\"\"\n",
    "    Collect hidden states from all transformer layers.\n",
    "    Returns a dictionary mapping layer indices to hidden state arrays.\n",
    "    \"\"\"\n",
    "    device = mt.model.device\n",
    "    num_layers = mt.model.config.num_hidden_layers\n",
    "    \n",
    "    # Initialize storage for each layer\n",
    "    layer_hidden_states = {i: [] for i in range(num_layers)}\n",
    "    \n",
    "    total_batches = (len(prompts) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for i in tqdm(range(0, len(prompts), batch_size), total=total_batches, desc=\"Collecting hidden states\"):\n",
    "        batch_prompts = prompts[i:i+batch_size]\n",
    "        inputs = mt.tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = mt.model(**inputs, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states  # Tuple of (num_layers+1) tensors\n",
    "            \n",
    "            # Process each layer's hidden states\n",
    "            for layer_idx in range(num_layers):\n",
    "                # Get hidden states for this layer (shape: [batch_size, seq_len, hidden_dim])\n",
    "                layer_output = hidden_states[layer_idx + 1]  # +1 because first is input embeddings\n",
    "                \n",
    "                # Take the last token's hidden state for each sequence\n",
    "                # This represents the final representation after processing the entire prompt\n",
    "                last_hidden = layer_output[:, -1, :].detach().cpu().float().numpy()\n",
    "                layer_hidden_states[layer_idx].append(last_hidden)\n",
    "    \n",
    "    # Concatenate all batches for each layer\n",
    "    for layer_idx in range(num_layers):\n",
    "        layer_hidden_states[layer_idx] = np.concatenate(layer_hidden_states[layer_idx], axis=0)\n",
    "        print(f\"Layer {layer_idx}: shape {layer_hidden_states[layer_idx].shape}\")\n",
    "    \n",
    "    return layer_hidden_states\n",
    "\n",
    "# %%\n",
    "print(\"Collecting hidden states for harmful prompts...\")\n",
    "harmful_hidden_states = collect_hidden_states(mt, harmful_prompts, batch_size=8)\n",
    "\n",
    "print(\"\\nCollecting hidden states for benign prompts...\")\n",
    "benign_hidden_states = collect_hidden_states(mt, benign_prompts, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Direction Vectors\n",
    "\n",
    "Compute the direction vector for each layer by taking the difference between \n",
    "mean harmful and mean benign hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_direction_vectors(harmful_states, benign_states):\n",
    "    \"\"\"\n",
    "    Compute direction vectors for each layer.\n",
    "    Direction = mean(harmful) - mean(benign)\n",
    "    \"\"\"\n",
    "    num_layers = len(harmful_states)\n",
    "    direction_vectors = {}\n",
    "    \n",
    "    for layer_idx in range(num_layers):\n",
    "        harmful_mean = np.mean(harmful_states[layer_idx], axis=0)\n",
    "        benign_mean = np.mean(benign_states[layer_idx], axis=0)\n",
    "        \n",
    "        # Direction points from benign to harmful\n",
    "        direction = harmful_mean - benign_mean\n",
    "        \n",
    "        # Normalize the direction vector\n",
    "        direction = direction / (np.linalg.norm(direction) + 1e-8)\n",
    "        \n",
    "        direction_vectors[layer_idx] = direction\n",
    "    \n",
    "    print(f\"Computed direction vectors for {num_layers} layers\")\n",
    "    return direction_vectors\n",
    "\n",
    "# %%\n",
    "direction_vectors = compute_direction_vectors(harmful_hidden_states, benign_hidden_states)\n",
    "\n",
    "# Print some statistics\n",
    "print(\"\\nDirection vector statistics:\")\n",
    "for layer_idx in [0, len(direction_vectors)//2, len(direction_vectors)-1]:\n",
    "    norm = np.linalg.norm(direction_vectors[layer_idx])\n",
    "    print(f\"Layer {layer_idx}: norm = {norm:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPE Generation with Direction Intervention\n",
    "\n",
    "Generate text while adding direction vectors to hidden states at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_repe_intervention(\n",
    "    mt,\n",
    "    prompt,\n",
    "    direction_vectors,\n",
    "    intervention_strength=1.0,\n",
    "    intervene=True,\n",
    "    intervention_layers=range(4, 9), \n",
    "    max_new_tokens=50\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate text with REPE intervention by adding direction vectors to hidden states.\n",
    "    \n",
    "    Args:\n",
    "        mt: ModelAndTokenizer object\n",
    "        prompt: Input prompt string\n",
    "        direction_vectors: Dictionary mapping layer indices to direction vectors\n",
    "        intervention_strength: Scaling factor for the direction vector\n",
    "        intervene: Whether to apply intervention\n",
    "        intervention_layers: Range or list of layer indices to intervene on\n",
    "        max_new_tokens: Maximum number of tokens to generate\n",
    "    \"\"\"\n",
    "    if hasattr(mt.tokenizer, 'apply_chat_template'):\n",
    "        formatted_prompt = mt.tokenizer.apply_chat_template(\n",
    "            [{\"role\": \"user\", \"content\": prompt}],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "    else:\n",
    "        formatted_prompt = prompt\n",
    "    \n",
    "    inputs = mt.tokenizer(formatted_prompt, return_tensors=\"pt\").to(mt.model.device)\n",
    "    \n",
    "    if not intervene:\n",
    "        # Generate without intervention (baseline)\n",
    "        with torch.no_grad():\n",
    "            outputs = mt.model.generate(\n",
    "                inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                pad_token_id=mt.tokenizer.pad_token_id\n",
    "            )\n",
    "        generation = mt.tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "        return generation\n",
    "    \n",
    "    # Create intervention hook for each layer\n",
    "    def make_repe_hook(layer_idx, direction_vector):\n",
    "        def hook(module, input, output):\n",
    "            # Handle tuple outputs (hidden_states, additional_outputs)\n",
    "            if isinstance(output, tuple):\n",
    "                hidden_states = output[0]\n",
    "            else:\n",
    "                hidden_states = output\n",
    "            \n",
    "            # Clone to avoid in-place modification\n",
    "            modified_states = hidden_states.clone()\n",
    "            \n",
    "            # Add direction vector to all positions\n",
    "            # Direction vector shape: [hidden_dim]\n",
    "            # Hidden states shape: [batch_size, seq_len, hidden_dim]\n",
    "            direction_tensor = torch.tensor(\n",
    "                direction_vector, \n",
    "                dtype=modified_states.dtype, \n",
    "                device=modified_states.device\n",
    "            )\n",
    "            \n",
    "            # Add scaled direction vector\n",
    "            modified_states = modified_states + intervention_strength * direction_tensor\n",
    "            \n",
    "            # Return in same format as input\n",
    "            if isinstance(output, tuple):\n",
    "                return (modified_states,) + output[1:]\n",
    "            else:\n",
    "                return modified_states\n",
    "        \n",
    "        return hook\n",
    "    \n",
    "    # Register hooks only for specified layers\n",
    "    hooks = []\n",
    "    for layer_idx in intervention_layers:\n",
    "        if layer_idx < mt.model.config.num_hidden_layers:\n",
    "            layer = mt.model.model.layers[layer_idx]\n",
    "            direction_vector = direction_vectors[layer_idx]\n",
    "            hook_handle = layer.register_forward_hook(make_repe_hook(layer_idx, direction_vector))\n",
    "            hooks.append(hook_handle)\n",
    "    \n",
    "    try:\n",
    "        # Generate with intervention\n",
    "        with torch.no_grad():\n",
    "            outputs = mt.model.generate(\n",
    "                inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                pad_token_id=mt.tokenizer.pad_token_id\n",
    "            )\n",
    "        generation = mt.tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    finally:\n",
    "        # Remove all hooks\n",
    "        for hook_handle in hooks:\n",
    "            hook_handle.remove()\n",
    "    \n",
    "    return generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Test REPE Intervention\n",
    "\n",
    "Test the intervention on harmful prompts and compute jailbreak success rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_harmful_data = pd.read_csv(\"analysis_data/advbench_behaviors.csv\")['Behavior']\n",
    "test_prompts = list(test_harmful_data)[100:120]  # Use different prompts for testing\n",
    "\n",
    "print(f\"Testing on {len(test_prompts)} harmful prompts...\")\n",
    "\n",
    "results = {\n",
    "    'baseline': {'harmful': 0, 'total': 0},\n",
    "    'intervened': {'harmful': 0, 'total': 0},\n",
    "    'detailed_results': []\n",
    "}\n",
    "\n",
    "# Test different intervention strengths\n",
    "intervention_strength = 3.0\n",
    "intervention_layers = range(3, 9)  \n",
    "\n",
    "for idx, prompt in enumerate(tqdm(test_prompts, desc=\"Testing prompts\")):\n",
    "    try:\n",
    "        # Generate baseline (no intervention)\n",
    "        baseline_gen = generate_with_repe_intervention(\n",
    "            mt, prompt, direction_vectors, \n",
    "            intervention_strength=intervention_strength,\n",
    "            intervene=False,\n",
    "            intervention_layers=intervention_layers,\n",
    "            max_new_tokens=50\n",
    "        )\n",
    "        \n",
    "        # Generate with REPE intervention\n",
    "        intervened_gen = generate_with_repe_intervention(\n",
    "            mt, prompt, direction_vectors,\n",
    "            intervention_strength=intervention_strength,\n",
    "            intervene=True,\n",
    "            intervention_layers=intervention_layers,\n",
    "            max_new_tokens=50\n",
    "        )\n",
    "        \n",
    "        # Judge both outputs\n",
    "        baseline_harmful = harmful_judge_from_strings(\n",
    "            prompt, baseline_gen, judge_model=(judge_tokenizer, judge_model_loaded)\n",
    "        )\n",
    "        intervened_harmful = harmful_judge_from_strings(\n",
    "            prompt, intervened_gen, judge_model=(judge_tokenizer, judge_model_loaded)\n",
    "        )\n",
    "        \n",
    "        # Update statistics\n",
    "        results['baseline']['total'] += 1\n",
    "        results['intervened']['total'] += 1\n",
    "        \n",
    "        if baseline_harmful:\n",
    "            results['baseline']['harmful'] += 1\n",
    "        if intervened_harmful:\n",
    "            results['intervened']['harmful'] += 1\n",
    "        \n",
    "        # Store detailed result\n",
    "        results['detailed_results'].append({\n",
    "            'prompt': prompt,\n",
    "            'baseline_generation': baseline_gen,\n",
    "            'baseline_harmful': baseline_harmful,\n",
    "            'intervened_generation': intervened_gen,\n",
    "            'intervened_harmful': intervened_harmful,\n",
    "            'jailbreak_successful': not baseline_harmful and intervened_harmful\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error on prompt {idx}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Calculate success rates\n",
    "baseline_jailbreak_rate = results['baseline']['harmful'] / results['baseline']['total'] if results['baseline']['total'] > 0 else 0\n",
    "intervened_jailbreak_rate = results['intervened']['harmful'] / results['intervened']['total'] if results['intervened']['total'] > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REPE INTERVENTION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBaseline (No Intervention):\")\n",
    "print(f\"  Harmful outputs: {results['baseline']['harmful']}/{results['baseline']['total']}\")\n",
    "print(f\"  Jailbreak rate: {baseline_jailbreak_rate*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nWith REPE Intervention (strength={intervention_strength}, layers=4-8):\")\n",
    "print(f\"  Harmful outputs: {results['intervened']['harmful']}/{results['intervened']['total']}\")\n",
    "print(f\"  Jailbreak rate: {intervened_jailbreak_rate*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nIntervention Effectiveness:\")\n",
    "print(f\"  Increase in jailbreak rate: {(intervened_jailbreak_rate - baseline_jailbreak_rate)*100:.2f}%\")\n",
    "\n",
    "# Count successful jailbreaks (baseline safe -> intervened harmful)\n",
    "successful_jailbreaks = sum(1 for r in results['detailed_results'] if r['jailbreak_successful'])\n",
    "print(f\"  Successful jailbreaks: {successful_jailbreaks}/{len(results['detailed_results'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"analysis_results/repe_intervention_results.json\",'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(\"\\nResults saved to analysis_results/repe_intervention_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
